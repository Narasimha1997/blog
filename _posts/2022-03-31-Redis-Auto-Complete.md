---
title: Building a secondary index of 1.5 million words for search and auto-complete using Redis cache
published: true
---
Recently I was playing around with building a [secondary index](https://practice.geeksforgeeks.org/problems/what-is-secondary-indices) for some documents to make them easily searchable using a search interface with auto-complete suggestions. I was interested to explore [Redis](https://redis.io/) for this task because it stores data completely in-memory. Though it is a simple Key-Value store with `O(1)` `GET` and `SET` operations, it provides many additional data-structures like Sorted Set, Hash Set, FIFO Queue etc. Moreover, it provides a simple protocol for communication over raw TCP (and UNIX) sockets - all these factors makes Redis a suitable candidate for building secondary indexes that reside completely in memory and can be used for retrieving results really quickly (with microsecond latencies). In this post, I will explain how we can exploit Redis to store large indexes for search and auto-complete and how we can further optimize it to scale the solution.

### The problem of prefix-search
The problem here is simple, given a list of N words, how will you search for a given word in that list quickly? Extending this problem further, how will get a list of M words that start with the given prefix? (example: If I have words - `[banana, bayer, bay]` then the prefix `bay` should return `[bay, bayer]`, similarly the prefix `ba` should return `[banana, bayer, bay]`) - In Computer Science, this is called "Prefix Search", because in a large search space of N strings, you are finding a set of M strings that start with the given prefix (M <= N), the naive way to solve this problem is to iterate over all the string one at a time and checking if it has the given substring as it's prefix, for that we can use [strcmp()](https://www.programiz.com/c-programming/library-function/string.h/strcmp) or [memcmp()](https://www.cplusplus.com/reference/cstring/memcmp/) - this solution is trivial, it works the best if we have a smaller search space, but this solution doesn't scale well if we have larger search spaces (like 1 million words) because this is a `O(N)` solution, as `N` increases the time taken to search also increases, to scale the solution well, we need a data-structure that takes less than O(N) time. The most efficient way to tell if a string is present in the given set is to use hash-table, we hash the string, if that hash is present in the set, then it exists - this is an ideal way of search where the time-complexity is almost O(1) in most of the cases, this solution scales well, but it fails to solve our problem, our problem here is to obtain a subset of strings that start with the same prefix in a given large set of strings. 

### Trie - a naive prefix search tree:
In the previous section we looked at O(n) solution which actually solved the problem, but not scalable, we also saw O(1) solution that is scalable but didn't actually solve the problem. One of the possible solutions that is slower than hash-table and faster than linear search is to use a trie. [Trie](https://en.wikipedia.org/wiki/Trie) data-structure is also known as prefix-tree. In simple words, every parent in the prefix tree is a prefix of the child. (i.e if we have two words `ban` and `bay` then the tree has a structure `b->a->(n, y)`, `b` is the prefix of `a` and `ba` is the prefix of `n` and `y`, so all the parents in that path is a prefix of the upcoming children in the same path). Here is a representation of prefix tree:

<div style="text-align: center">
    <img src="assets/redis-auto/trie12.jpg" alt="drawing" width="400" height="400"/>
</div>

The above trie can be used for efficient prefix search on words `[there, their, this, that, does, did]`. Once we have a prefix, we can traverse one node at a time based on each character in the prefix (if it exists in the trie), once our prefix ends we can do depth-first-search (or [DFS](https://www.geeksforgeeks.org/depth-first-search-or-dfs-for-a-graph/)) traversal over all the children starting from the node where our prefix ended to obtain all the possible strings that has the given prefix. This solution has time-complexity `O(M) + O(P + E)`, where `M` is the length of the prefix, `P` is the number of nodes that are in the sub-tree starting from the last prefix node and `E` is the number of edges involved in the sub-tree on which DFS is applied. (Note: Here the time-complexity of DFS is `O(P + E)` which has been added to `O(M)`, if we ignore the edges, then the time complexity is `O(M) + O(P)`), if you consider the time-complexity only to search the prefix then it is `O(M)`. This looks fine the time-complexity is far better than `O(N)`, but this is not always better, because most of the prefix search problems have smaller `M` value (i.e smaller prefix length), for example if I have 10000 strings in a set all starting with prefix `b->a`, then using `ba` as the prefix will lead to negligible `O(M)` and higher `O(P + E)`, but this is far better solution than linear search solution. Another problem is memory, we need large amount of memory to store prefix trees as `N` increases, because we need to allocate some space for storing pointers to the child nodes as well.In later sections, we will see another solution of implementing prefix search functionality using Redis sorted sets.

### Redis sorted sets
We looked at various approaches for prefix-search in previous sections, now let us implement one using Redis. As mentioned earlier, Redis is a key-value store that redis provides [many data-structures](https://redis.io/docs/manual/data-types/) like Sorted set, FIFO Queue, Hash set etc. A simple solution is to insert each string as a key with some dummy value (for example `banana:1`, `apple:1`, `applied:1`) into the key-value store (we can use `SET` command), this solution has `O(1)` time complexity for checking whether the given string exists or not, this is done by hashing the string and checking it against the key-value store, which is implemented using a hash-table (using `GET` command), but this method cannot be used for prefix search, for this we need to scan the entire key-value store using `<prefix>*` regular-expression, this can be done using [SCAN](https://redis.io/commands/scan/) command, the time complexity is `O(N)` because this approach is nothing but a linear search performed on all the keys in the hash-table. What we actually need is a data-structure that provides time-complexity lesser than `O(N)`, fortunately Redis provides [Sorted Set](https://redis.com/ebook/part-2-core-concepts/chapter-3-commands-in-redis/3-5-sorted-sets/), which provides `O(logN)` time-complexity insertion, deletion and retrievals. Sorted sets also called as `zsets` are built using combinations of two vanilla data structures - Hash Tables